{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probabilistic programming with PyMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "\n",
    "# should be 3.6 or greater\n",
    "import pymc3 as pm\n",
    "print(\"PyMC3 version {version}\".format(version=pm.__version__))\n",
    "\n",
    "import scipy.stats\n",
    "from pydataset import data\n",
    "\n",
    "# style matplotlib\n",
    "mpl.rcParams['figure.figsize'] = (6.0, 2.0)\n",
    "mpl.rcParams['figure.dpi'] = 120\n",
    "mpl.style.use('ggplot')\n",
    "\n",
    "# fix random seed for reproducbility\n",
    "np.random.seed(2019)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neat things\n",
    "\n",
    "* Demo of MCMC algorithms and their sampling properties: https://chi-feng.github.io/mcmc-demo/\n",
    "* Hamiltoninan MCMC visually explained (great animations): http://arogozhnikov.github.io/2016/12/19/markov_chain_monte_carlo.html\n",
    "* [A Conceptual Introduction to Hamiltonian Monte Carlo](https://arxiv.org/abs/1701.02434) An excellent paper on the theory of Hamiltonian Monte Carlo sampling\n",
    "* [Introduction to MCMC](http://www.inference.org.uk/mackay/erice.pdf) by David Mackay\n",
    "\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic purpose\n",
    "We will cover probabilistic **inference**. Rather than learning a single set of parameters by optimisation, we can model probability distributions over possible models that might be compatible with our data.  We'll use Monte Carlo sampling to make it simple and easy (if not very efficient) to work with probabilistic models. \n",
    "\n",
    "\n",
    "MCMC models:\n",
    "\n",
    "* **Data**, which we observe as a collection of examples.\n",
    "* A **model** which has **structure** (a DAG) and **parameters**\n",
    "* Part of the model is a likelihood function which has \"contact\" with data; these we will call **observed random variables**\n",
    "* Part of the model specifies distributions over parameters of the **observed variables**. These are **unobserved random variables**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyMC\n",
    "<a id=\"pymc\"> </a>\n",
    "We'll use the excellent PyMC module to do the inference. If you have questions about this module, you can read [this tutorial](http://arxiv.org/abs/1507.08050) or the [API docs](https://pymc-devs.github.io/pymc/). \n",
    "\n",
    "# Fitting a normal distribution\n",
    "## Bayesian Normal fitting\n",
    "We use Monte Carlo sampling to estimate the mean and standard deviation of some data.\n",
    "\n",
    "We assume we have data generated by a random process where $x \\sim \\mathcal{N}(\\mu, \\sigma^2)$, but we don't know $\\mu$ or $\\sigma$. We can place priors on $\\mu$ and $\\sigma$ and try and infer a distribution of plausible values.\n",
    "\n",
    "\n",
    "### Test data\n",
    "We generate some synthetic data from a known normal distribution. In this case we **know** that our data is in fact normally distributed, so our model assumptions are guaranteed to be correct. This isn't the typical case!!\n",
    "\n",
    "$$x \\sim \\mathcal{N}(-1, 1.5)$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## generate data with a known distribution\n",
    "## this will be our \"observed\" data\n",
    "\n",
    "n_samples = 30\n",
    "\n",
    "x_data = np.random.normal(-1,1.5, (n_samples,))\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.hist(x_data, bins=np.linspace(-5,5,15))\n",
    "ax.set_title(\"Histogram of data\")\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"Count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then create a model in PyMC. We have a single output variable `x`, which is **stochastic** and **observed**, and the data we have observed is `x_data`. As it is observed, we will use the likelihood of the data under different model settings to accept/reject samples in the process. \n",
    "\n",
    "We use $\\tau$ to represent the *reciprocal of variance*, as this is the standard model that PyMC uses. It makes it slightly easier to parameterise in some cases.\n",
    "\n",
    "We have a model:\n",
    "\n",
    "$$\n",
    "\\mu \\sim \\mathcal{N}(0, 10^2)\\\\\n",
    "\\sigma \\sim \\text{HalfNormal}(0.0, 10.0)\\\\\n",
    "x\\sim\\mathcal{N}(\\mu, \\sigma)\\\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "\n",
    "# plot the PDF of our prior\n",
    "xs = np.linspace(0, 100, 100)\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "\n",
    "# alpha = 1.0, beta = 20.0\n",
    "ax.plot(xs, scipy.stats.halfnorm(loc=0, scale=10).pdf(xs))\n",
    "\n",
    "ax.set_xlabel(\"$\\\\sigma$\")\n",
    "ax.set_ylabel(\"$p(\\\\sigma)$\")\n",
    "ax.set_title(\"Std. dev. $\\\\sigma$ \")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to set parents for every node. In this case, we have two parameters, $\\mu$ and $\\sigma$ to specify. We want to infer those, so we also make those stochastic variables, but unobserved (hidden). We specify the type of the distribution (here, `Normal` and `HalfNormal`) and we must then specify *those* parents. In this case, these are just concrete numbers (but we could go further if we wanted)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_model = pm.Model(name='flexible')\n",
    "\n",
    "with basic_model:\n",
    "    # Priors for unknown model parameters\n",
    "    mu = pm.Normal('mu', mu=0, sd=10)    \n",
    "    sigma = pm.HalfNormal('sigma', sd=10)\n",
    "\n",
    "        # Likelihood (sampling distribution) of observations\n",
    "    y_obs = pm.Normal('y_obs', mu=mu, sd=sigma, observed=x_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can show the graph of this model as a DAG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.model_to_graphviz(basic_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling\n",
    "With this model, we can then draw samples. In this case we are going to draw three things:\n",
    "* Posterior samples (i.e. samples of $\\mu$ and $\\sigma$)\n",
    "* Posterior predictive samples (i.e. samples of $y$ that should look like synthetic data)\n",
    "* Prior predictive samples (i.e. samples of $y$ drawn from the model *without* conditioning on data)\n",
    "* (we should also draw prior samples, but this isn't currently supported in `pymc3` directly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with basic_model:\n",
    "    trace = pm.sample(500)\n",
    "    # 50 samples *per* trace element = 50*500 here\n",
    "    ppc = pm.sample_posterior_predictive(trace, samples=50, model=basic_model)\n",
    "    # same number of samples from prior\n",
    "    ppc_prior = pm.sample_prior_predictive(samples=50*500, model=basic_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!theano-cache purge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traceplot\n",
    "The traceplot shows the histogram of posterior samples, and also the trace timeseries. This is useful in debugging poorly mixing chains. There will be no problem fitting in this instance, and everything will look nice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.traceplot(trace);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary \n",
    "We can print a summary of our variables, including:\n",
    "* mean and sd of posterior\n",
    "* simulation error\n",
    "* 95% interval around highest predicted density\n",
    "* number of effective samples from chain\n",
    "* Rhat (see below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.summary(trace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can show additional variables, for example the ordinary percentiles of the posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def trace_quantiles(x):    \n",
    "    return pd.DataFrame(pm.quantiles(x, [2.5, 25, 50, 75, 97.5]))\n",
    "    \n",
    "pm.summary(trace, stat_funcs = [trace_quantiles])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forest plot\n",
    "We can plot a forest plot, that shows the credible intervals for our parameter estimates,  and also \"R-Hat\". This is the Gelman-Rubin measure of convergence and it measures how well our sampling process has converged. It is always close to 1.0 and should be very close to 1.0. \n",
    "\n",
    "As a rough guide to interpreting `R-hat`\n",
    "* 1.00 good\n",
    "* 1.05 worrying\n",
    "* 1.1 bad things \n",
    "* worse than 1.1 sampling has gone badly wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.forestplot(trace, varnames=['flexible_mu', 'flexible_sigma']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Posterior histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.plots.plot_posterior(trace);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.plots.densityplot(trace);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autocorrelation\n",
    "Is our sampler taking uncorrelated samples? We can look at the **autocorrelation** of the samples. If they are perfectly unbiased, then this should be zero everywhere (no correlation between successive samples). We want to draw independent unbiased samples from the posterior, but an MCMC sampling process produces highly correlated samples (each sample depends on the previous). We want to measure and minimise that sample-to-sample correlation, which is captured by the autocorrelation.\n",
    "\n",
    "We can see how well the HMC chain drew independent samples by looking at the autocorrelation. This should be largely flat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.plots.autocorrplot(trace);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model comparison\n",
    "Let's compare with fitting a model which has a fixed standard deviation of $\\sigma=0.5$.\n",
    "This is simpler, but obviously a bad model for our data. We can then compare it to our more flexible model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_model = pm.Model(name='fixed')\n",
    "\n",
    "with fixed_model:\n",
    "\n",
    "    # Priors for unknown model parameters\n",
    "    mu = pm.Normal('mu', mu=0, sd=10)        \n",
    "\n",
    "        # Likelihood (sampling distribution) of observations\n",
    "    y_obs = pm.Normal('y_obs', mu=mu, sd=0.5, observed=x_data)\n",
    "    fixed_trace = pm.sample(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.traceplot(fixed_trace);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.summary(fixed_trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.plot_posterior(fixed_trace);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Information criterions: WAIC and LOO\n",
    "We can compute the Widely Applicable Information Criterion (WAIC) to get a sense of how well our models compare. This takes into account both the complexity of the models and the goodness-of-fit.  \n",
    "\n",
    "This is intended to approximate the out-of-sample error, i.e. the generalisation performance. The models with higher \"weight\" should be considered more viable. In this case, the `flexible` model is vastly better than the fixed model and gets all of the weight. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waic_compared = pm.stats.compare({basic_model:trace, fixed_model:fixed_trace})\n",
    "waic_compared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also compute this using the leave-one-out-cross-validation metric. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loo_compared = pm.stats.compare({basic_model:trace, fixed_model:fixed_trace}, ic='LOO')\n",
    "loo_compared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.plots.compareplot(waic_compared)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try\n",
    "Adjusting the fixed $\\sigma$ to 1.5 (the true value). The model comparison results will be reversed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **trace** is the collection of posterior samples, as a straightforward array. We can plot these using the built in visualisation tool:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also access them directly as arrays and plot them more flexibly (including showing draws from the predictive posterior):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trace_hist(trace, name):\n",
    "        fig = plt.figure()\n",
    "        fig.set_facecolor(\"white\")\n",
    "        n, bins, patches = plt.hist(trace.ravel(), normed=True, bins=50)                \n",
    "        max_n = np.max(n)\n",
    "        plt.title(\"Estimate of {var_name}\".format(var_name=name))\n",
    "        \n",
    "        # draw simple statistics\n",
    "        ctr_max = 0.5 * (bins[np.argmax(n)] + bins[np.argmax(n)+1])\n",
    "        plt.axvline(ctr_max, ls='-', color='r', lw=2, label='MAP')\n",
    "        plt.axvline(np.median(trace), ls='-', color='C1', lw=2, label='Median')\n",
    "        plt.axvline(np.mean(trace), ls=':', color='k', label='Expected')\n",
    "        # 90% credible interval\n",
    "        plt.axvline(np.percentile(trace, 5.0), ls=':', color='C1')\n",
    "        plt.axvline(np.percentile(trace, 95.0), ls=':', color='C1')\n",
    "        plt.fill_between(x=[np.percentile(trace, 5.0), np.percentile(trace, 95.0)], y1=max_n,\n",
    "                          color='C1', alpha=0.2, label='90% credible')\n",
    "        plt.text(np.mean(trace), 0.5*max_n, 'Mean')\n",
    "        plt.legend()\n",
    "        plt.gca().set_frame_on(False)\n",
    "        \n",
    "def show_trace(mcmc, vars_):\n",
    "    ## plot histograms of possible parameter values\n",
    "    # from the trace\n",
    "    for var,name in vars_.items():\n",
    "        \n",
    "        \n",
    "        trace = mcmc.get_values(var).ravel()\n",
    "        trace_hist(trace, name)\n",
    "        \n",
    "        \n",
    "def correlate_trace(mcmc, var_a, var_b):\n",
    "    # plot the correlation between two variables\n",
    "    # in the posterior as a scatter plot\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    ax.scatter(mcmc.get_values(var_a), \n",
    "               mcmc.get_values(var_b), s=1, alpha=0.1)\n",
    "    ax.set_aspect(1.0)\n",
    "    ax.set_xlabel(var_a)\n",
    "    ax.set_ylabel(var_b)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "\n",
    "show_trace(trace, {\"flexible_mu\":\"mean\", \n",
    "                  \"flexible_sigma\":\"std. dev\",\n",
    "                  })\n",
    "\n",
    "trace_hist(ppc['flexible_y_obs'], \"posterior predictive\")\n",
    "trace_hist(ppc_prior['flexible_y_obs'], \"prior predictive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see if there are any correlations in the parameters (there probably shouldn't be very strong correlation in this case, though we'd expect the estimated `std_dev` to be higher when the `mean` is further from the true mean)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlate_trace(trace, \"flexible_mu\", \"flexible_sigma\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changes to try:\n",
    "\n",
    "* Adjust $n$ to show effect of prior/posterior\n",
    "\n",
    "\n",
    "\n",
    "# Transformations of variables\n",
    "\n",
    "\n",
    "Fitting a uniform distribution instead, but using transformed variables. We parameterise in terms of centre and width of a uniform distribution, but transform these variables to the (lower, upper) form that the `Uniform` expects. This is a very simple example of transformations for inference.\n",
    "\n",
    "$$\n",
    "c \\sim \\mathcal{N}(0,10^2)\\\\\n",
    "w \\sim \\text{HalfNormal}(0.0, 5)\\\\\n",
    "l = c-w\\\\\n",
    "u = c+w\\\\\n",
    "x \\sim \\mathcal{U}(l,u)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# latent variables\n",
    "x_data = np.random.uniform(-2, 3, size=80)\n",
    "\n",
    "np.random.seed(1225)\n",
    "\n",
    "## WARNING ##\n",
    "## This model is not well-specified. It is possible for the\n",
    "# likelihood to be zero for some parameter settings, which breaks\n",
    "# pymc3 sampling process and is generally a very bad thing to do\n",
    "# This is why the results are forced into a single\n",
    "# chain when sampling and the seed is fixed. Inference *does*\n",
    "# work, kind of.\n",
    "## WARNING ##\n",
    "uniform_model = pm.Model()\n",
    "\n",
    "with uniform_model:\n",
    "    # Priors for unknown model parameters\n",
    "    c = pm.Normal('c', mu=0, sd=10)    \n",
    "    w = pm.HalfNormal('w', sd=5)\n",
    "    l = c - w\n",
    "    u = c + w\n",
    "    y_obs = pm.Uniform('y_obs', lower=l,  upper=u, observed=x_data)\n",
    "\n",
    "# display the graphical model\n",
    "pm.model_to_graphviz(uniform_model)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with uniform_model:\n",
    "    trace = pm.sample(2000, cores=1)\n",
    "     # 50 samples *per* trace element = 50*500 here\n",
    "    ppc = pm.sample_posterior_predictive(trace, samples=50, model=uniform_model)\n",
    "    # same number of samples from prior\n",
    "    ppc_prior = pm.sample_prior_predictive(samples=50*500, model=uniform_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.traceplot(trace);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.plots.plot_posterior(trace);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_trace(trace, {\"c\":\"centre\", \n",
    "                  \"w\":\"width\"})\n",
    "trace_hist(ppc['y_obs'], \"Posterior predictive\")\n",
    "trace_hist(ppc_prior['y_obs'], \"Prior predictive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graphical models\n",
    "<a id=\"graphical\"> </a>\n",
    "\n",
    "Transformations of expressions to graphs is familiar to most computer scientists -- it is an essential part of most optimising compilers. For example, the equation of a straight line might be written as a graph (this is how a compiler would break down the expression):\n",
    "\n",
    "<img src=\"imgs/ymxc.png\" width=\"300px\">\n",
    "\n",
    "## Adding unknowns\n",
    "If we have multiple dependent random variables whose distribution we want to infer, we can draw a graph of dependencies to form a *graphical model*.  This explictly models dependencies between **random variables** (i.e. ones we don't know the value of precisely) and inference can be performed on the entire graph. \n",
    "\n",
    "**In CS terms, we are writing expressions down without fixing the variables, and then allowing the distribution of the values to be inferred when we observe data.** This inference process narrows down the likely range a random variable could take on (hopefully!).\n",
    "\n",
    "In a **probabilistic graphical model**, some nodes in the graph are **observed** -- that is we know their state because we have explicity measured it, and others are **unobserved** -- we know (or have guessed) the form of their distribution but not the parameters of that distribution. Some dependencies are deterministic (i.e. fully defined by the values of their parents), while others are stochastic. We can infer the **posterior** distribution of unobserved nodes by integrating over the possible values that could have occured given the observed values.\n",
    "\n",
    "We can modify our straight line equation to write a model for **linear regression**:\n",
    "\n",
    "<img src=\"imgs/ymxc_stochastic.png\">\n",
    "\n",
    "All we need to do is specify that we expected the output $y$ to be normally distributed around the equation of a line given by $m$ and $c$; we can now **infer** $\\sigma, m, c$ from observed data. Or we can fix any of them, and infer the remainder (if, e.g. we knew in advance that $c=0$). Our assumption here is that we will observe data which has a **latent structure** modelled by a linear dependence on a variable $x$, plus some normally-distributed observation noise.\n",
    "\n",
    "**Note that we must put *some* prior distribution on every stochastic node and we can only observe stochastic nodes.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's implement the linear regression model in the intro in practice, using PyMC to build a graphical model and then run MCMC to sample from the posterior (i.e. estimate the distribution of random variables after seeing some evidence)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Bayesian Linear Regression with pymc\n",
    "### We use Monte Carlo sampling to estimate the distribution of a linear function with a normally\n",
    "### distributed error, given some observed data.\n",
    "### Vaguely based on: http://matpalm.com/blog/2012/12/27/dead_simple_pymc/ and http://sabermetricinsights.blogspot.co.uk/2014/05/bayesian-linear-regression-with-pymc.html\n",
    "\n",
    "\n",
    "## generate data with a known distribution\n",
    "## this will be our \"observed\" data\n",
    "x = np.sort(np.random.uniform(0,20, (50,)))\n",
    "m = 2\n",
    "c = 15\n",
    "\n",
    "# Add on some measurement noise, with std. dev. 3.0\n",
    "epsilon = data = np.random.normal(0, 3, x.shape)\n",
    "y = m * x + c + epsilon\n",
    "\n",
    "plt.plot(x,y, '.', label=\"Datapoints\")\n",
    "plt.plot(x, m*x+c, '--', lw=3, label=\"True\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"x\")\n",
    "plt.xlabel(\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now, set up the PyMC model\n",
    "\n",
    "regression_model = pm.Model()\n",
    "\n",
    "with regression_model:\n",
    "    \n",
    "\n",
    "    ## specify the prior distribution of the unknown line function variables\n",
    "    ## Here, we assume a normal distribution over m and c\n",
    "    m = pm.Normal('m', mu=0, sd=10)\n",
    "    c = pm.Normal('c', mu=0, sd=50)\n",
    "    \n",
    "    std = pm.HalfCauchy('std', beta=20)\n",
    "    x_obs = pm.Normal('x_obs', mu=0, sd=1, observed=x)\n",
    "    \n",
    "    line = m * x_obs + c\n",
    "    y_obs = pm.Normal('y_obs', mu=line, sd=std, observed=y)\n",
    "    \n",
    "    \n",
    "# display the graphical model\n",
    "pm.model_to_graphviz(regression_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with regression_model:\n",
    "    trace = pm.sample(500)\n",
    "     # 50 samples *per* trace element = 50*500 here\n",
    "    ppc = pm.sample_posterior_predictive(trace, samples=50, model=uniform_model)\n",
    "    # same number of samples from prior\n",
    "    ppc_prior = pm.sample_prior_predictive(samples=50*500, model=uniform_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.plots.forestplot(trace)\n",
    "pm.plots.traceplot(trace)\n",
    "pm.plots.plot_posterior(trace)\n",
    "pm.summary(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_hist( ppc[\"y_obs\"], \"Posterior predictive\")\n",
    "trace_hist( ppc_prior[\"y_obs\"], \"Prior predictive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draws from the posterior predictive model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "[<img src=\"https://imgs.xkcd.com/comics/error_bars.png\">](https://xkcd.com/2110)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## now plot overlaid samples from the linear function\n",
    "## Note: this *ignores* the error distribution we've estimated\n",
    "## If we drew samples from the true posterior predictive, \n",
    "# we'd see much greater spread\n",
    "## in possible simulations\n",
    "ms = trace[\"m\"]\n",
    "cs = trace[\"c\"]\n",
    "\n",
    "\n",
    "plt.title(\"Sampled fits\")\n",
    "plt.plot(x, y, '.', label=\"Observed\")\n",
    "\n",
    "xf = np.linspace(-20,40,200)\n",
    "for m,c in zip(ms[::20], cs[::20]):    \n",
    "    plt.plot(xf, xf*m+c, 'g-', alpha=0.01)\n",
    "plt.plot(x, x*m+c, '--', label=\"True\", zorder=100)\n",
    "plt.legend()\n",
    "plt.xlim(-10,30)\n",
    "plt.ylim(-20,70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "\n",
    "# Logistic regression example: discrete dependent variable\n",
    "On ye olde iris dataset, using the four flower measurements to predict whether or not\n",
    "the species is `setosa` or another type of iris.\n",
    "\n",
    "We estimate a set of coefficients $\\beta_0, \\beta_1, \\dots$ and use the logistic function to transform the a linear model into a probability for a Bernoulli variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pydataset import data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "iris = data(\"iris\")\n",
    "iris[\"is_setosa\"] = np.where(iris[\"Species\"]==\"setosa\", 1, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into a train and test set\n",
    "iris_train, iris_test = train_test_split(iris)\n",
    "print(\"Train size\", iris_train.shape)\n",
    "print(\"Test size\", iris_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model:\n",
    "\n",
    "We have some coefficients $\\beta$, which feed into our logistic function to produce $l$, and $y$ is Bernoulli distributed (0 or 1) with probability $l$.\n",
    "\n",
    "$$\n",
    "\\beta_i \\sim \\mathcal{N}(0, 5)\\\\\n",
    "l = \\frac{1}{1+e^{\\beta_0 + \\sum_i \\beta_i x_i}}\\\\\n",
    "y \\sim \\mathcal{B}(l)\\\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binary prediction of \"is_setosa\", using the four attributes\n",
    "# of the flower configuration\n",
    "\n",
    "# predictors (standardised)\n",
    "xs = np.array(iris_train.iloc[:, 0:4])\n",
    "x_standardised = (xs - xs.mean()) / xs.std()\n",
    "\n",
    "# observed values\n",
    "ys = np.array(iris_train[\"is_setosa\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_model = pm.Model()\n",
    "\n",
    "import theano.tensor as tt\n",
    "\n",
    "with logistic_model:    \n",
    "    x_std = pm.Normal(\"x_std\", mu=0, sd=1, observed=x_standardised)    \n",
    "    \n",
    "    # 4 regression coefficients\n",
    "    betas = pm.Normal(\"betas\", mu=0, sd=0.1, shape=(5,))\n",
    "    \n",
    "    logistic = 1.0 / (1 + tt.exp(-(betas[0] + betas[1] * x_std[:,0] +\n",
    "                                              betas[2] * x_std[:,1] +\n",
    "                                              betas[3] * x_std[:,2] +\n",
    "                                              betas[4] * x_std[:,3]\n",
    "                                  )))\n",
    "    \n",
    "    y = pm.Bernoulli(\"y\", p=logistic, observed=ys)\n",
    "    \n",
    "# display the graphical model\n",
    "pm.model_to_graphviz(logistic_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with logistic_model:\n",
    "    trace = pm.sample(500, cores=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.plots.forestplot(trace)\n",
    "pm.plots.traceplot(trace)\n",
    "pm.plots.plot_posterior(trace)\n",
    "pm.summary(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,12))\n",
    "\n",
    "for i in range(5):\n",
    "    ax = fig.add_subplot(3,2,i+1)    \n",
    "    trace_hist(trace[\"betas\"][:,i], \"$\\\\beta_{i}$\".format(i=i))\n",
    "    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics\n",
    "\n",
    "# write link function for use in prediction\n",
    "def logistic_predict(betas, x_std):\n",
    "    return 1.0 / (1 + np.exp(-(betas[0] + np.sum(betas[1:] * x_std, axis=1))))\n",
    "\n",
    "# standardise predictors in test set\n",
    "test_x = iris_test.iloc[:, 0:4]\n",
    "test_x = (test_x - np.mean(test_x))/np.std(test_x)\n",
    "\n",
    "y_true = iris_test[\"is_setosa\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions\n",
    "We can draw samples from the posterior and then use the regression coefficients to make new predictions. Annoyingly, \n",
    "we have to rewrite the logistic function, but this is easy to do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot for true versus predicted\n",
    "fig1 = plt.figure()\n",
    "ax1 = fig1.add_subplot(1,1,1)\n",
    "ax1.set_xlabel(\"True\")\n",
    "ax1.set_ylabel(\"Predicted\")\n",
    "ax1.set_title(\"True versus predicted\")\n",
    "\n",
    "# plot for ROC curve\n",
    "fig2 = plt.figure()\n",
    "ax2 = fig2.add_subplot(1,1,1)\n",
    "ax2.set_xlabel(\"FPR\")\n",
    "ax2.set_xlabel(\"TPR\")\n",
    "\n",
    "confusions = []\n",
    "beta_trace = trace[\"betas\"]\n",
    "\n",
    "# predict \n",
    "for i in range(6):\n",
    "    # choose a random set of betas\n",
    "    beta_ix = np.random.randint(0, beta_trace.shape[0]-1)\n",
    "    beta_vec = beta_trace[beta_ix, :]        \n",
    "    y_pred =  logistic_predict(beta_vec, test_x)    \n",
    "    ax1.scatter(y_true+np.random.normal(0,0.01,\n",
    "                                        y_true.shape),\n",
    "                y_pred,s=20)\n",
    "    # bias is due to unbalanced classes (I think)\n",
    "    y_class = np.where(y_pred<0.5, 0, 1)\n",
    "    confusion = sklearn.metrics.confusion_matrix(y_true, y_class)    \n",
    "    confusions.append(confusion)\n",
    "        \n",
    "    fpr, tpr, thresholds = sklearn.metrics.roc_curve(y_true, y_pred)\n",
    "    ax2.plot(fpr, tpr)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution of confusion matrices\n",
    "We can show the (samples from) distribution of confusion matrices if we want:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(1,2,1)\n",
    "ax1.imshow(np.mean(confusions, axis=0))\n",
    "ax2 = fig.add_subplot(1,2,2)\n",
    "ax2.imshow(np.std(confusions, axis=0))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show samples from the confusion matrices\n",
    "confusions = np.array(confusions)\n",
    "# some tensor reshaping fun...\n",
    "confusion_pad = np.stack([confusions, np.zeros_like(confusions)]).swapaxes(0,1)\n",
    "flat = np.concatenate(np.concatenate(confusion_pad, axis=0), axis=1)\n",
    "plt.imshow(flat, cmap='magma')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "# Switchpoint model: more complex logic\n",
    "\n",
    "<img src=\"poverty_rates.png\">\n",
    "\n",
    "*[Source: https://ourworldindata.org/extreme-history-methods]*\n",
    "\n",
    "Data not provided, so hand-digitised via https://apps.automeris.io/wpd/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "# load data from a string\n",
    "\n",
    "data = StringIO(\"\"\"year,poverty_rate\n",
    "1819.8097502972653, 83.88791593695271\n",
    "1849.6789536266351, 81.646234676007\n",
    "1869.655172413793, 75.48161120840629\n",
    "1889.821640903686, 71.6987740805604\n",
    "1909.6076099881093, 65.67425569176883\n",
    "1928.8228299643283, 56.42732049036777\n",
    "1949.7502972651605, 54.8861646234676\n",
    "1959.6432818073722, 44.09807355516638\n",
    "1969.7265160523186, 35.69176882661996\n",
    "1979.8097502972653, 31.62872154115587\n",
    "1991.6052318668253, 23.782837127845866\n",
    "2004.922711058264, 13.695271453590195\n",
    "2001.8787158145064, 17.19789842381782\n",
    "1999.0249702734839, 19.159369527145344\n",
    "1995.9809750297266, 19.299474605954472\n",
    "1987.0392390011891, 24.483362521891436\n",
    "1989.8929845422117, 24.483362521891436\n",
    "1983.9952437574316, 27.98598949211906\n",
    "1980.9512485136743, 33.450087565674266\n",
    "1992.936979785969, 22.521891418563897\"\"\")\n",
    "\n",
    "poverty_ = pd.read_csv(data)\n",
    "# deleting the dodgy data point\n",
    "# uncomment to experiment\n",
    "# poverty = poverty_.drop(labels=[6])\n",
    "\n",
    "poverty = poverty_\n",
    "poverty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poverty.plot(x='year', y='poverty_rate', kind='scatter')\n",
    "plt.gca().set_frame_on(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis\n",
    "We model the data with a linear regression, but where there is a switchpoint, where the regression coefficient changes (i.e. piecewise linear with two pieces). We estimate both the regression coefficients at each position and the location of the switchpoint.\n",
    "\n",
    "$$s \\sim \\mathcal{N}{(1960, 100)}\\\\\n",
    "\\beta_0 \\sim \\mathcal{N}(50, 10)\\\\\n",
    "\\beta_1 \\sim \\mathcal{N}(-1, 2)\\\\\n",
    "\\beta_2 \\sim \\mathcal{N}(-1, 2)\\\\\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mu = \\begin{cases}\n",
    "x<s & \\beta_0 + \\beta_1 (x-s)\\\\\n",
    "x>s & \\beta_0 + \\beta_2 (x-s)\\\\\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "\n",
    "$$\n",
    "\\tau \\sim \\mathcal{\\Gamma}(1, 10) \\\\\n",
    "y \\sim \\mathcal{N}(\\mu, \\frac{1}{\\tau})\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "switch_model = pm.Model()\n",
    "\n",
    "import theano.tensor as tt\n",
    "mean_prate = 50.0 # poverty[\"poverty_rate\"].mean()\n",
    "mean_year = 1960 # poverty[\"year\"].mean()\n",
    "with switch_model:    \n",
    "    year = pm.Normal(\"year\", mu=0, sd=1, observed=poverty[\"year\"]-mean_year)\n",
    "    # 3 betas\n",
    "    poverty_at_switchpoint = pm.Normal(\"poverty_at_switchpoint\", mu=0, sd=20.0)\n",
    "    \n",
    "    left_slope = pm.Normal(\"left_slope\", mu=0, sd=1)\n",
    "    right_slope = pm.Normal(\"right_slope\", mu=0, sd=1)\n",
    "    switchpoint = pm.Normal(\"switchpoint\", mu=0, sd=100)\n",
    "    \n",
    "    \n",
    "    knee = 1.0\n",
    "    switch_value = (tt.tanh(knee * (switchpoint - year)) + 1) / 2.0\n",
    "    \n",
    "    switch_value = (switch_value * (poverty_at_switchpoint+left_slope*(year-switchpoint)) +\n",
    "    (1-switch_value) * (poverty_at_switchpoint+right_slope*(year-switchpoint)))\n",
    "                          \n",
    "    sigma = pm.HalfNormal(\"sigma\", sd=5)\n",
    "    y = pm.Normal(\"y\", mu=switch_value, sd=sigma, observed=poverty[\"poverty_rate\"]-mean_prate)\n",
    "    trace = pm.sample(1000)\n",
    "    \n",
    "# display the graphical model\n",
    "pm.model_to_graphviz(switch_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.plots.forestplot(trace)\n",
    "pm.plots.traceplot(trace)\n",
    "pm.plots.plot_posterior(trace)\n",
    "pm.summary(trace)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poverty.plot(x='year', y='poverty_rate', kind='scatter')\n",
    "ax = plt.gca()\n",
    "ax.set_frame_on(False)\n",
    "ax.set_ylabel(\"Global poverty rate\")\n",
    "ax.set_xlim(1800,2020)\n",
    "ax.set_ylim(0,100)\n",
    "plt.gcf().set_facecolor('white')\n",
    "\n",
    "left_slope = trace[\"left_slope\"]\n",
    "right_slope = trace[\"right_slope\"]\n",
    "intercept = trace[\"poverty_at_switchpoint\"] + mean_prate\n",
    "switch_year = trace[\"switchpoint\"] + mean_year\n",
    "\n",
    "\n",
    "for i in range(1500):\n",
    "    ix = np.random.randint(0, len(left_slope-1))\n",
    "    s = switch_year[ix]\n",
    "    x1 = np.clip(s-200, 1800, 2020)\n",
    "    x2 = s\n",
    "    x3 = np.clip(s+200, 1800, 2020)\n",
    "    y1 = intercept[ix] + left_slope[ix] * (x1-s)\n",
    "    y2 = intercept[ix] \n",
    "    y3 = intercept[ix] + right_slope[ix] * (x3-s)\n",
    "    ax.plot([x1,x2,x3], [y1,y2,y3], 'C2', lw=0.05, alpha=0.05)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "# A simple mixture model: discrete + continuous latent variables\n",
    "## When things get tricky\n",
    "\n",
    "We can include both **discrete** and **continuous** variables. A very important case is where we have a **mixture model**. That is, we believe our observations come from one of a number of distributions. For example, in modelling human heights, we might expect height to be normally distributed, but to have two different distributions for men and women.\n",
    "\n",
    "<img src=\"imgs/mixture.png\">\n",
    "\n",
    "It is very straightforward to add this to a PyMC graphical model; it is just another random variable to infer. However, sampling is another matter.\n",
    "\n",
    "In this case we do full **clustering**.  That is, we suppose the data is generated by three different processes, each of which is normal with some unknown mean and variance, and we have to estimate:\n",
    "\n",
    "* The parameters of each of $n$ process/clusters\n",
    "* The index of the cluster/process that each observation belongs to.\n",
    "\n",
    "This means we have one discrete parameter for *every* data point; we need to label each data point during inference. This is very hard to sample from, as it is a high-dimensional discrete space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Adapted from the example given at \n",
    "## http://stackoverflow.com/questions/18987697/how-to-model-a-mixture-of-3-normals-in-pymc\n",
    "\n",
    "# if you touch this seed, the fit breaks :)\n",
    "# this is *not* a stable fit with these parameters!\n",
    "np.random.seed(2028)\n",
    "n = 3\n",
    "ndata = 2000\n",
    "\n",
    "\n",
    "## Generate synthetic mixture-of-normals data, \n",
    "# with means at -50,0,+50, and std. dev of 5,10,1\n",
    "v = np.random.randint( 0, n, ndata)\n",
    "data = ((v==0)*(np.random.normal(50,5,ndata)) + \n",
    "        (v==1)*(np.random.normal(-50,10,ndata)) + \n",
    "        (v==2)*np.random.normal(0,1,ndata))\n",
    "\n",
    "\n",
    "## Plot the original data\n",
    "plt.hist(data, bins=50);  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## A Dirichlet distribution specifies the distribution over categories\n",
    "## All 1 means that every category is equally likely\n",
    "dd = mc.Dirichlet('dd', theta=(1,)*n)\n",
    "\n",
    "## This variable \"selects\" the category (i.e. the normal distribution)\n",
    "## to use. The Dirichlet distribution sets the prior over the categories.\n",
    "category = mc.Categorical('category', \n",
    "                          p=dd, size=ndata)\n",
    "\n",
    "## Now we set our priors the precision and mean of each normal distribution\n",
    "## Note the use of \"size\" to generate a **vector** of variables \n",
    "# (i.e. one for each category)\n",
    "\n",
    "## We expect the precision of each normal to be Gamma distributed \n",
    "# (this mainly forces it to be positive!)\n",
    "precs = mc.Gamma('precs', alpha=1, \n",
    "                 beta=10, size=n)\n",
    "\n",
    "## And the means of the normal to be normally distributed, with a precision of 0.001 \n",
    "# (i.e. std. dev 1000)\n",
    "means = mc.Normal('means', 0, 1.0/(100*100), size=n)\n",
    "\n",
    "## These deterministic functions link the means of the observed distribution \n",
    "# to the categories\n",
    "## They just select one of the elements of the mean/precision vector, \n",
    "# given the current value of category\n",
    "## The input variables must be specified in the parameters, so that \n",
    "# PyMC knows which variables to pass to it\n",
    "@mc.deterministic\n",
    "def mean(category=category, means=means):\n",
    "    return means[category]\n",
    "\n",
    "@mc.deterministic\n",
    "def prec(category=category, precs=precs):\n",
    "    return precs[category]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now we specify the variable we observe -- which is normally distributed, *but*\n",
    "## we don't know the mean or precision. \n",
    "# Instead, we pass the **functions** mean() and pred()\n",
    "## which will be used at each sampling step.\n",
    "## We specify the observed values of this node, and tell PyMC these are observed \n",
    "## This is all that is needed to specify the model\n",
    "obs = mc.Normal('obs', mean, prec, \n",
    "                value=data, observed = True)\n",
    "\n",
    "## Now we just bundle all the variables together for PyMC\n",
    "model = mc.Model({'dd': dd,\n",
    "              'category': category,\n",
    "              'precs': precs,\n",
    "              'means': means,\n",
    "              'obs': obs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "show_dag(model)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcmc = mc.MCMC(model)\n",
    "\n",
    "## Now we tell the sampler what method to use\n",
    "## Metropolis works well, but we must tell PyMC to use a specific\n",
    "## discrete sampler for the category variable to get good results in a reasonable time\n",
    "mcmc.use_step_method(mc.AdaptiveMetropolis, \n",
    "                     model.means)\n",
    "mcmc.use_step_method(mc.AdaptiveMetropolis,\n",
    "                     model.precs)\n",
    "mcmc.use_step_method(mc.DiscreteMetropolis, \n",
    "                     model.category) ## this step is key!\n",
    "mcmc.use_step_method(mc.AdaptiveMetropolis, \n",
    "                     model.dd)\n",
    "\n",
    "## Run the sampler with 5 different chains\n",
    "mcmc.sample(iter=150000, burn=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.hist(mcmc.trace('means', chain=None).gettrace()[:], normed=True, bins=np.linspace(-100,100,50))\n",
    "plt.title(\"Estimated means\")\n",
    "plt.legend(['Component 1', 'Component 2', 'Component 3'])\n",
    "plt.figure()\n",
    "## show the result in terms of std. dev. (i.e sqrt(1.0/precision))\n",
    "plt.title(\"Estimated std. dev\")\n",
    "plt.hist(np.sqrt(1.0/mcmc.trace('precs', chain=None).gettrace()[:]), normed=True, \n",
    "         bins=np.linspace(0,15,50))\n",
    "plt.legend(['Component 1', 'Component 2', 'Component 3'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mixture modelling without classification\n",
    "\n",
    "If all we wanted to do was to estimate the parameters of the mixture (i.e. the PDF), and *not* perform the clustering process that assigns labels to datapoints, then we can write a simpler model (\"marginalising out the discrete variables\"). We write a custom stochastic variable representing a mixture-of-Gaussian likelihood function with vector parameters. This then lets us estimate the distribution but does not identify the classes each data point belongs to. This has no discrete parameters and is easier to fit. We can try and do this class labeling post hoc, assigning each observation to the most probable class, but this loses the uncertainty about class membership that we have in the full model above.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import theano.tensor as tt\n",
    "with pm.Model() as model:\n",
    "    w = pm.Dirichlet('w', np.ones(n))\n",
    "    \n",
    "    mu = pm.Normal('mu', 0., 10., shape=n, testval=[-10, 0, 10])\n",
    "    sigma = pm.HalfCauchy('sd', 20, shape=n)\n",
    "    \n",
    "    # trick: force the order of mu to be sequential, so that the posterior\n",
    "    # samples are stable across multiple chains. This makes the likelihood 0\n",
    "    # if the order of mu is not increasing\n",
    "    p = pm.Potential('order', tt.switch(tt.extra_ops.diff(mu)<0, -np.inf, 0).sum())\n",
    "    \n",
    "    x_obs = pm.NormalMixture('x_obs', w, mu, sd=sigma, observed=data)\n",
    "    trace = pm.sample(1000, cores=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.plots.traceplot(trace);\n",
    "pm.plots.plot_posterior(trace);\n",
    "pm.stats.summary(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import theano.tensor as tt\n",
    "\n",
    "    \n",
    "with pm.Model() as model:\n",
    "    w = pm.Dirichlet('w', np.ones(n))    \n",
    "    mu_0 = pm.Normal('mu_0', 0., 50.)\n",
    "    mu_n = pm.HalfNormal('mu_n',  50., shape=n-1)\n",
    "    sigma = pm.HalfCauchy('sd', 10, shape=n)    \n",
    "    # alternative; force mus to be increasing by nature\n",
    "    mu_transform = pm.Deterministic('mu_s', tt.cumsum(tt.concatenate([tt.stack(mu_0), mu_n])))\n",
    "    x_obs = pm.NormalMixture('x_obs', w, mu_transform, sd=sigma, observed=data)\n",
    "    trace = pm.sample(1000, cores=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.plots.traceplot(trace);\n",
    "pm.plots.plot_posterior(trace);\n",
    "pm.stats.summary(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.linspace(-100,100,200)\n",
    "\n",
    "plt.hist(mcmc.trace(\"means\")[:,0], bins=bins);\n",
    "plt.hist(mcmc.trace(\"means\")[:,1], bins=bins);\n",
    "plt.hist(mcmc.trace(\"means\")[:,2], bins=bins);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.linspace(0,20,50)\n",
    "to_std = lambda x: np.sqrt(1.0/x)\n",
    "plt.hist(to_std(mcmc.trace(\"precs\")[:,0]))\n",
    "plt.hist(to_std(mcmc.trace(\"precs\")[:,1]))\n",
    "plt.hist(to_std(mcmc.trace(\"precs\")[:,2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imputation in quadratic regression\n",
    "<a id=\"imputation\"> </a>\n",
    "\n",
    "In PyMC, variables can be **observed** (fixed) or **unobserved** (random). PyMC cycles through the array of known values for the **observed** variables and updates the rest of the graph.\n",
    "\n",
    "\n",
    "PyMC implements this using **imputation**, where certain missing values in an observed variable can be inferred (*imputed*) from the rest of the model. This creates new random variables and then infers the missing values. **Masked arrays** are used to implement imputation; these allow arrays to have \"blank\" values, that PyMC can fill in automatically.\n",
    "\n",
    "This approach creates one new random variable per missing data item; this can create very large models if you are not careful!\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Example, using very simple quadratic regression model \n",
    "import numpy.ma as ma # masked array support\n",
    "\n",
    "## generate the data for the regression\n",
    "x = np.sort(np.random.uniform(0, 20, (50,)))\n",
    "m = 2\n",
    "c = 15\n",
    "# Add on some measurement noise, with std. dev. 3.0\n",
    "epsilon = data = np.random.normal(0, 50, x.shape)\n",
    "y = m * x * x + c + epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now the imputation; we will try and infer missing some missing values of y (we still have the corresponding x)\n",
    "## mark last three values of y invalid\n",
    "y_impute = y[:]\n",
    "\n",
    "n_missing = 6\n",
    "impute_ixs = np.sort(np.random.randint(0, len(y)-1, size=n_missing))\n",
    "y_impute[impute_ixs] = 0\n",
    "y_impute = ma.masked_equal(y_impute,0)\n",
    "print(\"Y masked for imputation:\", y_impute) # we will see the last three entries with --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model (exactly as before, except we switch \"y_impute\" for \"y\")\n",
    "\n",
    "with pm.Model() as model:\n",
    "    m_inf = pm.Normal('m', mu=0, sd=10)    \n",
    "    c_inf = pm.Normal('c', mu=0, sd=50)    \n",
    "    std = pm.HalfNormal('std', sd=50)\n",
    "    x_obs = pm.Normal('x_obs', observed=x)\n",
    "    y_obs = pm.Normal('y_obs', mu=m_inf*x_obs*x_obs+c_inf, sd=std, observed=y_impute)\n",
    "    trace = pm.sample(1000, cores=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.plots.traceplot(trace);\n",
    "pm.plots.plot_posterior(trace);\n",
    "pm.stats.summary(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "## now we will have three entries in the y_obs trace from this run\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "\n",
    "## the original data\n",
    "ax.plot(x, y, '.', label=\"Data\")\n",
    "\n",
    "ax.plot(x, x*x*m+c, ':', label=\"True\")\n",
    "\n",
    "m_sample = trace[\"m\"]\n",
    "c_sample = trace[\"c\"]\n",
    "\n",
    "# plot samples from the quadratic fits\n",
    "\n",
    "for i in range(50):\n",
    "    m_post = np.random.choice(m_sample)\n",
    "    c_post = np.random.choice(c_sample)\n",
    "    ax.plot(x, x*x*m_post + c_post, \"g\", alpha=0.05,\n",
    "           label=\"Posterior\" if i==0 else None)\n",
    "    \n",
    "imputed = trace.get_values('y_obs_missing')\n",
    "\n",
    "# samples from posterior predicted for the missing values of y\n",
    "for i in range(len(impute_ixs)):\n",
    "        \n",
    "    ax.axvline(x[impute_ixs[i]], c='C1', alpha=0.1, label=\"Imputed\" if i==0 else None)\n",
    "    # plot the actual imputed data points\n",
    "    ax.scatter(np.tile(x[impute_ixs[i]], \n",
    "                        (len(imputed), 1)), \n",
    "                        imputed[:,i], s=2, c='C3', marker='_', \n",
    "                        alpha=0.25)\n",
    "\n",
    "ax.set_xlim(-1,25)\n",
    "ax.set_xticks(np.arange(0,25,5))\n",
    "ax.set_xticklabels(np.arange(0,25,5))\n",
    "ax.legend()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------"
   ]
  }
 ],
 "metadata": {
  "jupytext_format_version": "1.0",
  "kernelspec": {
   "display_name": "Python [conda env:theano]",
   "language": "python",
   "name": "conda-env-theano-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
